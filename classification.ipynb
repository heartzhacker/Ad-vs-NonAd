{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7541586,"sourceType":"datasetVersion","datasetId":4391652},{"sourceId":7541813,"sourceType":"datasetVersion","datasetId":4391808},{"sourceId":7545450,"sourceType":"datasetVersion","datasetId":4394199},{"sourceId":7545462,"sourceType":"datasetVersion","datasetId":4394206},{"sourceId":7545513,"sourceType":"datasetVersion","datasetId":4394246}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import MobileNet\nfrom tensorflow.keras import layers, models","metadata":{"execution":{"iopub.status.busy":"2024-02-04T12:17:58.040933Z","iopub.execute_input":"2024-02-04T12:17:58.041297Z","iopub.status.idle":"2024-02-04T12:17:58.047494Z","shell.execute_reply.started":"2024-02-04T12:17:58.041268Z","shell.execute_reply":"2024-02-04T12:17:58.046631Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"IMAGE_SIZE = (224, 224)\nBATCH_SIZE = 32\nEPOCHS = 10","metadata":{"execution":{"iopub.status.busy":"2024-02-04T12:17:58.222265Z","iopub.execute_input":"2024-02-04T12:17:58.223113Z","iopub.status.idle":"2024-02-04T12:17:58.227140Z","shell.execute_reply.started":"2024-02-04T12:17:58.223080Z","shell.execute_reply":"2024-02-04T12:17:58.226200Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_data_dir = '/kaggle/input/ad-vs-nonad/Data'  \ntrain_ad_dir = '/kaggle/input/ad-vs-nonad/Data/Ad'\ntrain_non_ad_dir = '/kaggle/input/ad-vs-nonad/Data/Non-Ad'","metadata":{"execution":{"iopub.status.busy":"2024-02-04T12:17:58.395153Z","iopub.execute_input":"2024-02-04T12:17:58.395869Z","iopub.status.idle":"2024-02-04T12:17:58.399937Z","shell.execute_reply.started":"2024-02-04T12:17:58.395835Z","shell.execute_reply":"2024-02-04T12:17:58.398949Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    rescale=1./255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    validation_split=0.2\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-04T12:17:58.571122Z","iopub.execute_input":"2024-02-04T12:17:58.571481Z","iopub.status.idle":"2024-02-04T12:17:58.576439Z","shell.execute_reply.started":"2024-02-04T12:17:58.571451Z","shell.execute_reply":"2024-02-04T12:17:58.575435Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_generator = train_datagen.flow_from_directory(\n    train_data_dir,\n    target_size=IMAGE_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='binary',\n    subset='training'\n)\nvalidation_generator = train_datagen.flow_from_directory(\n    train_data_dir,\n    target_size=IMAGE_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='binary',\n    subset='validation'\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-04T12:17:58.745205Z","iopub.execute_input":"2024-02-04T12:17:58.745541Z","iopub.status.idle":"2024-02-04T12:18:05.972193Z","shell.execute_reply.started":"2024-02-04T12:17:58.745515Z","shell.execute_reply":"2024-02-04T12:18:05.971451Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Found 5043 images belonging to 2 classes.\nFound 1260 images belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"base_model = MobileNet(weights='imagenet', include_top=False, input_shape=(224, 224, 3))","metadata":{"execution":{"iopub.status.busy":"2024-02-04T12:18:05.973570Z","iopub.execute_input":"2024-02-04T12:18:05.973878Z","iopub.status.idle":"2024-02-04T12:18:07.816710Z","shell.execute_reply.started":"2024-02-04T12:18:05.973853Z","shell.execute_reply":"2024-02-04T12:18:07.815917Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n17225924/17225924 [==============================] - 0s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"for layer in base_model.layers[:-3]:\n    layer.trainable = False","metadata":{"execution":{"iopub.status.busy":"2024-02-04T12:18:07.817953Z","iopub.execute_input":"2024-02-04T12:18:07.818250Z","iopub.status.idle":"2024-02-04T12:18:07.827097Z","shell.execute_reply.started":"2024-02-04T12:18:07.818224Z","shell.execute_reply":"2024-02-04T12:18:07.825365Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model = models.Sequential([\n    base_model,\n    layers.GlobalAveragePooling2D(),\n    layers.Dense(512, activation='relu'),\n    layers.Dropout(0.5),\n    layers.Dense(256, activation='relu'),\n    layers.Dropout(0.5), \n    layers.Dense(128, activation='relu'),\n    layers.Dropout(0.5),\n    layers.Dense(64, activation='relu'),\n    layers.Dropout(0.5),\n    layers.Dense(1, activation='sigmoid')\n])\n","metadata":{"execution":{"iopub.status.busy":"2024-02-04T12:18:07.831962Z","iopub.execute_input":"2024-02-04T12:18:07.832280Z","iopub.status.idle":"2024-02-04T12:18:08.195126Z","shell.execute_reply.started":"2024-02-04T12:18:07.832251Z","shell.execute_reply":"2024-02-04T12:18:08.194112Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2024-02-04T12:18:08.196354Z","iopub.execute_input":"2024-02-04T12:18:08.196655Z","iopub.status.idle":"2024-02-04T12:18:08.227240Z","shell.execute_reply.started":"2024-02-04T12:18:08.196630Z","shell.execute_reply":"2024-02-04T12:18:08.226247Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    train_generator,\n    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n    validation_data=validation_generator,\n    validation_steps=validation_generator.samples // BATCH_SIZE,\n    epochs=EPOCHS\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-04T12:18:08.228461Z","iopub.execute_input":"2024-02-04T12:18:08.229159Z","iopub.status.idle":"2024-02-04T12:32:00.325634Z","shell.execute_reply.started":"2024-02-04T12:18:08.229131Z","shell.execute_reply":"2024-02-04T12:32:00.324634Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1707049095.330169     114 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"157/157 [==============================] - 120s 718ms/step - loss: 0.2468 - accuracy: 0.9066 - val_loss: 0.2952 - val_accuracy: 0.9479\nEpoch 2/10\n157/157 [==============================] - 79s 506ms/step - loss: 0.0733 - accuracy: 0.9796 - val_loss: 0.0574 - val_accuracy: 0.9832\nEpoch 3/10\n157/157 [==============================] - 79s 506ms/step - loss: 0.0289 - accuracy: 0.9900 - val_loss: 0.1365 - val_accuracy: 0.9631\nEpoch 4/10\n157/157 [==============================] - 80s 507ms/step - loss: 0.0440 - accuracy: 0.9893 - val_loss: 0.1204 - val_accuracy: 0.9784\nEpoch 5/10\n157/157 [==============================] - 79s 502ms/step - loss: 0.0325 - accuracy: 0.9924 - val_loss: 0.0631 - val_accuracy: 0.9840\nEpoch 6/10\n157/157 [==============================] - 79s 504ms/step - loss: 0.0238 - accuracy: 0.9910 - val_loss: 0.1346 - val_accuracy: 0.9792\nEpoch 7/10\n157/157 [==============================] - 78s 500ms/step - loss: 0.0186 - accuracy: 0.9946 - val_loss: 0.2138 - val_accuracy: 0.9688\nEpoch 8/10\n157/157 [==============================] - 79s 504ms/step - loss: 0.0181 - accuracy: 0.9952 - val_loss: 0.4285 - val_accuracy: 0.9135\nEpoch 9/10\n157/157 [==============================] - 78s 500ms/step - loss: 0.0155 - accuracy: 0.9958 - val_loss: 0.0309 - val_accuracy: 0.9872\nEpoch 10/10\n157/157 [==============================] - 79s 505ms/step - loss: 0.0189 - accuracy: 0.9944 - val_loss: 0.0414 - val_accuracy: 0.9864\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.preprocessing import image\n\nimg_path = '/kaggle/input/testing-adddddd/ad4.jpeg' \nimg = image.load_img(img_path, target_size=(224, 224))\nimg_array = image.img_to_array(img)\nimg_array = np.expand_dims(img_array, axis=0)\nimg_array /= 255.0 ","metadata":{"execution":{"iopub.status.busy":"2024-02-04T12:33:18.806633Z","iopub.execute_input":"2024-02-04T12:33:18.807541Z","iopub.status.idle":"2024-02-04T12:33:18.814357Z","shell.execute_reply.started":"2024-02-04T12:33:18.807505Z","shell.execute_reply":"2024-02-04T12:33:18.813514Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"predictions = model.predict(img_array)\n\nif predictions[0][0] > 0.5:\n    print(\"The image is predicted to be a non-ad creative.\")\nelse:\n    print(\"The image is predicted to be an ad creative.\")","metadata":{"execution":{"iopub.status.busy":"2024-02-04T12:33:22.484931Z","iopub.execute_input":"2024-02-04T12:33:22.485569Z","iopub.status.idle":"2024-02-04T12:33:22.557035Z","shell.execute_reply.started":"2024-02-04T12:33:22.485538Z","shell.execute_reply":"2024-02-04T12:33:22.556138Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 21ms/step\nThe image is predicted to be an ad creative.\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.models import save_model\nmodel.save('final_model.h5')","metadata":{"execution":{"iopub.status.busy":"2024-02-04T12:33:28.263570Z","iopub.execute_input":"2024-02-04T12:33:28.264179Z","iopub.status.idle":"2024-02-04T12:33:28.477266Z","shell.execute_reply.started":"2024-02-04T12:33:28.264147Z","shell.execute_reply":"2024-02-04T12:33:28.476257Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Assuming `base_model` is the first layer in your Sequential model\nbase_model = model.layers[0]\n\n# Get the names of all layers in the base model\nlayer_names = [layer.name for layer in base_model.layers]\n\n# Identify the last convolutional layer\nlast_conv_layer_name = None\nfor name in reversed(layer_names):\n    if 'conv' in name:\n        last_conv_layer_name = name\n        break\n\n# Print the name of the last convolutional layer\nprint(\"Last Convolutional Layer:\", last_conv_layer_name)\nlayer_names","metadata":{"execution":{"iopub.status.busy":"2024-02-04T13:44:57.437759Z","iopub.execute_input":"2024-02-04T13:44:57.438578Z","iopub.status.idle":"2024-02-04T13:44:57.449490Z","shell.execute_reply.started":"2024-02-04T13:44:57.438547Z","shell.execute_reply":"2024-02-04T13:44:57.448587Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Last Convolutional Layer: conv_pw_13_relu\n","output_type":"stream"},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"['input_1',\n 'conv1',\n 'conv1_bn',\n 'conv1_relu',\n 'conv_dw_1',\n 'conv_dw_1_bn',\n 'conv_dw_1_relu',\n 'conv_pw_1',\n 'conv_pw_1_bn',\n 'conv_pw_1_relu',\n 'conv_pad_2',\n 'conv_dw_2',\n 'conv_dw_2_bn',\n 'conv_dw_2_relu',\n 'conv_pw_2',\n 'conv_pw_2_bn',\n 'conv_pw_2_relu',\n 'conv_dw_3',\n 'conv_dw_3_bn',\n 'conv_dw_3_relu',\n 'conv_pw_3',\n 'conv_pw_3_bn',\n 'conv_pw_3_relu',\n 'conv_pad_4',\n 'conv_dw_4',\n 'conv_dw_4_bn',\n 'conv_dw_4_relu',\n 'conv_pw_4',\n 'conv_pw_4_bn',\n 'conv_pw_4_relu',\n 'conv_dw_5',\n 'conv_dw_5_bn',\n 'conv_dw_5_relu',\n 'conv_pw_5',\n 'conv_pw_5_bn',\n 'conv_pw_5_relu',\n 'conv_pad_6',\n 'conv_dw_6',\n 'conv_dw_6_bn',\n 'conv_dw_6_relu',\n 'conv_pw_6',\n 'conv_pw_6_bn',\n 'conv_pw_6_relu',\n 'conv_dw_7',\n 'conv_dw_7_bn',\n 'conv_dw_7_relu',\n 'conv_pw_7',\n 'conv_pw_7_bn',\n 'conv_pw_7_relu',\n 'conv_dw_8',\n 'conv_dw_8_bn',\n 'conv_dw_8_relu',\n 'conv_pw_8',\n 'conv_pw_8_bn',\n 'conv_pw_8_relu',\n 'conv_dw_9',\n 'conv_dw_9_bn',\n 'conv_dw_9_relu',\n 'conv_pw_9',\n 'conv_pw_9_bn',\n 'conv_pw_9_relu',\n 'conv_dw_10',\n 'conv_dw_10_bn',\n 'conv_dw_10_relu',\n 'conv_pw_10',\n 'conv_pw_10_bn',\n 'conv_pw_10_relu',\n 'conv_dw_11',\n 'conv_dw_11_bn',\n 'conv_dw_11_relu',\n 'conv_pw_11',\n 'conv_pw_11_bn',\n 'conv_pw_11_relu',\n 'conv_pad_12',\n 'conv_dw_12',\n 'conv_dw_12_bn',\n 'conv_dw_12_relu',\n 'conv_pw_12',\n 'conv_pw_12_bn',\n 'conv_pw_12_relu',\n 'conv_dw_13',\n 'conv_dw_13_bn',\n 'conv_dw_13_relu',\n 'conv_pw_13',\n 'conv_pw_13_bn',\n 'conv_pw_13_relu']"},"metadata":{}}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.applications.mobilenet import preprocess_input, decode_predictions\nfrom tensorflow.keras.preprocessing import image\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\n\nmodel = load_model('/kaggle/working/final_model.h5')\n\nbase_model = model.layers[0]\nlast_conv_layer_name = 'conv_pw_13_relu' \n\nimg_path = '/kaggle/input/testing-adddddd/ad4.jpeg'  # Replace with the path to your image\nimg = image.load_img(img_path, target_size=(224, 224))\nimg_array = image.img_to_array(img)\nimg_array = np.expand_dims(img_array, axis=0)\nimg_array = preprocess_input(img_array)\n\ndef make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n    grad_model = tf.keras.models.Model(\n        model.inputs, [model.get_layer('dense_4').output, model.output]\n    )\n#     print(grad_model)\n    with tf.GradientTape() as tape:\n        last_conv_layer_output, preds = grad_model(img_array)\n        if pred_index is None:\n            pred_index = tf.argmax(preds[0])\n        class_channel = preds[:, pred_index]\n    grads = tape.gradient(class_channel, last_conv_layer_output)\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n    last_conv_layer_output = last_conv_layer_output[0]\n    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n    return heatmap.numpy()\n\npredictions = model.predict(img_array)\n\nif predictions[0][0] > 0.5:\n    print(\"The image is predicted to be a non-ad creative.\")\nelse:\n    print(\"The image is predicted to be an ad creative.\")\nmodel.layers[-1].activation = None\nheatmap = make_gradcam_heatmap(img_array, model, 'dense_4')\n\n# plt.matshow(heatmap)\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-04T14:08:18.415418Z","iopub.execute_input":"2024-02-04T14:08:18.415835Z","iopub.status.idle":"2024-02-04T14:08:20.260961Z","shell.execute_reply.started":"2024-02-04T14:08:18.415803Z","shell.execute_reply":"2024-02-04T14:08:20.259704Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 478ms/step\nThe image is predicted to be an ad creative.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","Cell \u001b[0;32mIn[51], line 45\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe image is predicted to be an ad creative.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     44\u001b[0m model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mactivation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m heatmap \u001b[38;5;241m=\u001b[39m \u001b[43mmake_gradcam_heatmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdense_4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# plt.matshow(heatmap)\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# plt.show()\u001b[39;00m\n","Cell \u001b[0;32mIn[51], line 31\u001b[0m, in \u001b[0;36mmake_gradcam_heatmap\u001b[0;34m(img_array, model, last_conv_layer_name, pred_index)\u001b[0m\n\u001b[1;32m     29\u001b[0m     class_channel \u001b[38;5;241m=\u001b[39m preds[:, pred_index]\n\u001b[1;32m     30\u001b[0m grads \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(class_channel, last_conv_layer_output)\n\u001b[0;32m---> 31\u001b[0m pooled_grads \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m last_conv_layer_output \u001b[38;5;241m=\u001b[39m last_conv_layer_output[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     33\u001b[0m heatmap \u001b[38;5;241m=\u001b[39m last_conv_layer_output \u001b[38;5;241m@\u001b[39m pooled_grads[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, tf\u001b[38;5;241m.\u001b[39mnewaxis]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/weak_tensor_ops.py:88\u001b[0m, in \u001b[0;36mweak_tensor_unary_op_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     87\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     90\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__Mean_device_/job:localhost/replica:0/task:0/device:GPU:0}} Invalid reduction dimension (2 for input with 2 dimension(s) [Op:Mean]"],"ename":"InvalidArgumentError","evalue":"{{function_node __wrapped__Mean_device_/job:localhost/replica:0/task:0/device:GPU:0}} Invalid reduction dimension (2 for input with 2 dimension(s) [Op:Mean]","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}